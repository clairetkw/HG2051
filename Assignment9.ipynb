{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Teo Kai Wen\"\n",
    "COLLABORATORS = \"Prof Goodman, Ser Han\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9\n",
    "\n",
    "**due:** Wednesday, 13 November\n",
    "\n",
    "This assignment gives you practice with supervised classification.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "We will build models to classify the genre of paragraphs of text. The data will come from the Brown corpus, since its categories are divided by genre.\n",
    "\n",
    "First let's inspect the size of each genre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category         # Paras  # Sents  # Words\n",
      "---------------  -------  -------  -------\n",
      "adventure           1387     4637    69342\n",
      "belles_lettres      1405     7209   173096\n",
      "editorial           1003     2997    61604\n",
      "fiction             1043     4249    68488\n",
      "government           851     3032    70117\n",
      "hobbies             1119     4193    82345\n",
      "humor                254     1053    21695\n",
      "learned             1418     7734   181888\n",
      "lore                1203     4881   110299\n",
      "mystery             1164     3886    57169\n",
      "news                2234     4623   100554\n",
      "religion             369     1716    39399\n",
      "reviews              629     1751    40704\n",
      "romance             1253     4431    70022\n",
      "science_fiction      335      948    14470\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "print('Category         # Paras  # Sents  # Words')\n",
    "print('---------------  -------  -------  -------')\n",
    "for genre in brown.categories():\n",
    "    print('{:<15}  {:>7}  {:>7}  {:>7}'.format(\n",
    "        genre,\n",
    "        len(brown.paras(categories=genre)),\n",
    "        len(brown.sents(categories=genre)),\n",
    "        len(brown.words(categories=genre))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment let's just use the smaller genres: `humor`, `religion`, `reviews`, and `science_fiction`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['humor', 'religion', 'reviews', 'science_fiction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, note that `brown.paras()` returns a list of paragraphs, and each paragraph is a list of sentences, and each sentence is a list of words. Schematically, that is:\n",
    "\n",
    "```\n",
    "brown.paras()       ->  [para, ...]\n",
    "[para, ...]         ->  [[sent, ...], ...]\n",
    "[[sent, ...], ...]  ->  [[[word, ...], ...], ...]\n",
    "```\n",
    "\n",
    "Since our classifiers will need to work with lists of words, the following function should help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w1', 'w2', 'w3', 'w4']\n",
      "[['w1', 'w2'], ['w3', 'w4'], ['w1', 'w2'], ['w3', 'w4']]\n",
      "['w1', 'w2', 'w3', 'w4', 'w1', 'w2', 'w3', 'w4']\n"
     ]
    }
   ],
   "source": [
    "def flatten(list_of_lists):\n",
    "    return [item for lst in list_of_lists for item in lst]\n",
    "\n",
    "# now to test it out\n",
    "sents = [['w1', 'w2'], ['w3', 'w4']]  # list of sentences\n",
    "paras = [sents, sents]                # list of paragraphs\n",
    "\n",
    "print(flatten(sents))\n",
    "print(flatten(paras))\n",
    "print(flatten(flatten(paras)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Create the labeled data (2 points)\n",
    "\n",
    "In order to build a classifier, we need to create some labeled test and training data. Do the following:\n",
    "\n",
    "* Use `brown.paras()` as above to get all paragraphs for a genre\n",
    "  * Make a tuple that pairs each paragraph with its genre: `(para, genre)`\n",
    "  * Use `k` to calculate how many pairs is `1/k` of the total for the genre\n",
    "  * Put 1/10 of the pairs for each genre in `test_paras`\n",
    "  * Put the remaining 9/10 of the pairs in `train_paras`\n",
    "* Repeat for each genre\n",
    "\n",
    "**Note:** you cannot just do `brown.paras(categories=genres)` because then you won't know which category each paragraph belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7e3086b0530ca0051a1e15f85e1d6c98",
     "grade": false,
     "grade_id": "cell-20255b66cd3b3908",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  1431\n",
      "test:    156\n"
     ]
    }
   ],
   "source": [
    "train_paras = []\n",
    "test_paras = []\n",
    "k = 10\n",
    "\n",
    "for genre in genres:\n",
    "    temp_list = [(para, genre) for para in brown.paras(categories=genre)]\n",
    "    index = int((1/k)*len(temp_list))\n",
    "    train = temp_list[index:]\n",
    "    test = temp_list[:index]\n",
    "    train_paras += train\n",
    "    test_paras += test \n",
    "    \n",
    "print('train: {:>5}'.format(len(train_paras)))\n",
    "print('test:  {:>5}'.format(len(test_paras)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6e102ca1a94ae8602765fcbea02880a7",
     "grade": true,
     "grade_id": "cell-0bb4d3a5d474aebc",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humor:\n",
      "       expected  observed\n",
      "TRAIN       228       229\n",
      "TEST         25        25\n",
      "\n",
      "religion:\n",
      "       expected  observed\n",
      "TRAIN       332       333\n",
      "TEST         36        36\n",
      "\n",
      "reviews:\n",
      "       expected  observed\n",
      "TRAIN       566       567\n",
      "TEST         62        62\n",
      "\n",
      "science_fiction:\n",
      "       expected  observed\n",
      "TRAIN       301       302\n",
      "TEST         33        33\n",
      "\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Check that train and test are the right size for each genre.\n",
    "# Don't check exactly, but +- c to account for rounding error.\n",
    "c = 3  # a small constant\n",
    "for genre in genres:\n",
    "    total = len(brown.paras(categories=genre))\n",
    "    expected_test = int(total * (1 / k))\n",
    "    expected_train = int(total * ((k-1) / k))\n",
    "    observed_test = len([pair for pair in test_paras if pair[1] == genre])\n",
    "    observed_train = len([pair for pair in train_paras if pair[1] == genre])\n",
    "    print(genre + ':')\n",
    "    print('       expected  observed')\n",
    "    print('TRAIN  {:>8}  {:>8}'.format(expected_train, observed_train))\n",
    "    print('TEST   {:>8}  {:>8}'.format(expected_test, observed_test))\n",
    "    print()\n",
    "    assert (observed_train - c) < expected_train < (observed_train + c)\n",
    "    assert (observed_test - c) < expected_test < (observed_test + c)\n",
    "\n",
    "print('All tests passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Create a feature extractor function (2 points)\n",
    "\n",
    "We have pairs of `(para, genre)`, but we need `(feature_dict, genre)` for training a classifier. Create a function `features()` that takes a paragraph and returns a dictionary of features. For now, just create feature types for each word (the `flatten()` function will help), such as `contains(film)` set to the value `True`. For instance, if the paragraph was just `[['Great', 'film', '!']]`, then the feature dict would be `{'contains(Great)': True, 'contains(film)': True, 'contains(!)': True}`. Do not normalize the strings (e.g., downcasing them, etc.). Whether a word appears once or multiple times, the feature value is `True`. You do not need to make missing features with the value `False` as the classifier will figure this out automatically.\n",
    "\n",
    "**Note:** the `features()` function takes a paragraph, not a `(para, genre)` pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "75b64f6fc2e17e55cc5e1b1792bfb563",
     "grade": false,
     "grade_id": "cell-26b11ca80d552210",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contains(The)': True, 'contains(incident)': True, 'contains(,)': True, 'contains(aside)': True, 'contains(from)': True, 'contains(reflecting)': True, 'contains(on)': True, \"contains(Welch's)\": True, 'contains(political)': True, 'contains(career)': True, 'contains(had)': True, 'contains(all)': True, 'contains(but)': True, 'contains(wrecked)': True, 'contains(his)': True, 'contains(home)': True, 'contains(life)': True, 'contains(.)': True, 'contains(He)': True, 'contains(never)': True, 'contains(rested)': True, 'contains(until)': True, 'contains(he)': True, 'contains(discovered)': True, 'contains(who)': True, 'contains(the)': True, 'contains(culprit)': True, 'contains(was)': True, 'contains(and)': True, 'contains(when)': True, 'contains(did)': True, 'contains(vowed)': True, 'contains(vengeance)': True, 'contains(Viola)': True, 'contains(Lake)': True, 'contains(if)': True, 'contains(ever)': True, 'contains(chance)': True, 'contains(came)': True, 'contains(way)': True, 'contains(And)': True, 'contains(here)': True, 'contains(it)': True, 'contains(!)': True, 'contains(By)': True, 'contains(such)': True, 'contains(innocent)': True, 'contains(actions)': True, 'contains(are)': True, 'contains(human)': True, 'contains(tragedies)': True, 'contains(sometimes)': True, 'contains(set)': True, 'contains(in)': True, 'contains(motion)': True}\n"
     ]
    }
   ],
   "source": [
    "def features(para):\n",
    "    \"\"\"Return the features for each word in each sentence in *para*.\"\"\"\n",
    "    d = {}\n",
    "    for word in flatten(para):\n",
    "        key = 'contains({})'.format(word)\n",
    "        d[key] = True\n",
    "    return d\n",
    "\n",
    "print(features(train_paras[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "62ceffb083c738f5c6ebb6f8ad6962ea",
     "grade": true,
     "grade_id": "cell-6a7f6672c6f2aaec",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "assert features([['Great', 'film', '!']]) == {'contains(Great)': True, 'contains(film)': True, 'contains(!)': True}\n",
    "assert features([['yeet', 'yeet', 'yeet']]) == {'contains(yeet)': True}\n",
    "print('All tests passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Train a Naive Bayes model (2 points)\n",
    "\n",
    "Do the following to train a Naive Bayes classifier:\n",
    "\n",
    "* Apply `features()` to the paragraphs in the `(para, genre)` pairs of `train_paras` and create `(feature_dict, genre)` pairs; store in a new list `train`\n",
    "* Do the same for `test_paras`; store in a new list `test`\n",
    "* Train an `nltk.NaiveBayesClassifier()` with `train`\n",
    "* Evaluate on `test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "91c0ad36d45e332959e649216a497228",
     "grade": true,
     "grade_id": "cell-ba1f66b2d14f1541",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4807692307692308"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "train = [(features(para), genre) for para, genre in train_paras]\n",
    "test = [(features(para), genre) for para, genre in test_paras]\n",
    "\n",
    "nb = nltk.NaiveBayesClassifier.train(train)\n",
    "nltk.classify.accuracy(nb, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see an accuracy around 48%, which is better than random chance of four categories (25%) or if we always picked the majority genre (`reviews`: 567/1431 = 40%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: Create an alternative feature extractor function (2 points)\n",
    "\n",
    "Create a new feature extractor function, `features2()`, and do as before with the following changes:\n",
    "\n",
    "* downcase each word\n",
    "* remove stopwords\n",
    "* lemmatize each remaining word with [`nlkt.stem.WordNetLemmatizer`](http://www.nltk.org/api/nltk.stem.html#nltk.stem.wordnet.WordNetLemmatizer)\n",
    "\n",
    "You can use the stopwords like this:\n",
    "\n",
    "```python\n",
    ">>> from nltk.corpus import stopwords\n",
    ">>> stop = set(stopwords.words('english'))\n",
    ">>> 'the' in stop\n",
    "True\n",
    "```\n",
    "\n",
    "And the WordNetLemmatizer like this:\n",
    "\n",
    "```python\n",
    ">>> from nltk.stem import WordNetLemmatizer\n",
    ">>> wnl = WordNetLemmatizer()\n",
    ">>> wnl.lemmatize('laughs')\n",
    "'laugh'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2d73166cfa42ebb8198f3822534f3db0",
     "grade": false,
     "grade_id": "cell-65b94e900c3a3e40",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contains(incident)': True, 'contains(,)': True, 'contains(aside)': True, 'contains(reflecting)': True, \"contains(welch's)\": True, 'contains(political)': True, 'contains(career)': True, 'contains(wrecked)': True, 'contains(home)': True, 'contains(life)': True, 'contains(.)': True, 'contains(never)': True, 'contains(rested)': True, 'contains(discovered)': True, 'contains(culprit)': True, 'contains(vowed)': True, 'contains(vengeance)': True, 'contains(viola)': True, 'contains(lake)': True, 'contains(ever)': True, 'contains(chance)': True, 'contains(came)': True, 'contains(way)': True, 'contains(!)': True, 'contains(innocent)': True, 'contains(action)': True, 'contains(human)': True, 'contains(tragedy)': True, 'contains(sometimes)': True, 'contains(set)': True, 'contains(motion)': True}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "def features2(para):\n",
    "    \"\"\"Return the features for each normalized word in each sentence in *para*.\"\"\"\n",
    "    d2 = {}\n",
    "    for word in flatten(para):\n",
    "        word = word.lower()\n",
    "        if word not in stop:\n",
    "            word = wnl.lemmatize(word)\n",
    "            key = 'contains({})'.format(word)\n",
    "            d2[key] = True\n",
    "    return d2\n",
    "    \n",
    "print(features2(train_paras[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a59100a63c2048f979469bdd3284a973",
     "grade": true,
     "grade_id": "cell-e56ac8af009246bf",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "assert features2([['Great', 'film', '!']]) == {'contains(great)': True, 'contains(film)': True, 'contains(!)': True}\n",
    "assert features2([['Lots', 'of', 'laughs']]) == {'contains(lot)': True, 'contains(laugh)': True}\n",
    "print('All tests passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Train a Naive Bayes model with normalized features (2 points)\n",
    "\n",
    "Now do as you did for Q3 but using `features2()` instead of `features()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "157ceffb30ad81f5387374c75e5aaa33",
     "grade": true,
     "grade_id": "cell-9376e0c91c83e270",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5512820512820513"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "train2 = [(features2(para), genre) for para, genre in train_paras]\n",
    "test2 = [(features2(para), genre) for para, genre in test_paras]\n",
    "\n",
    "nb2 = nltk.NaiveBayesClassifier.train(train2)\n",
    "nltk.classify.accuracy(nb2, test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see an accuracy of around 55%; a 7% improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
