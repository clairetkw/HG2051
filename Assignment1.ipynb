{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Teo Kai Wen\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "There are two coding parts and one short answer part to this assignment.\n",
    "\n",
    "For these you will use the first verse and refrain from the Mexican folk song [*De Colores*](https://en.wikipedia.org/wiki/De_Colores). Run the following to import the NLTK and make the `de_colores` variable available later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# In Python, a string with 3 quotes can span multiple lines\n",
    "de_colores = '''\n",
    "De colores, de colores\n",
    "Se visten los campos en la primavera.\n",
    "\n",
    "De colores, de colores\n",
    "Son los pajaritos que vienen de afuera.\n",
    "\n",
    "De colores, de colores\n",
    "Es el arco iris que vemos lucir.\n",
    "\n",
    "Y por eso los grandes amores\n",
    "De muchos colores me gustan a mí.\n",
    "\n",
    "Y por eso los grandes amores\n",
    "De muchos colores me gustan a mí.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preface: Making Functions\n",
    "\n",
    "We have not yet covered how to create Python functions, but consider the following function that adds two numbers:\n",
    "\n",
    "```python\n",
    "def add(x, y):\n",
    "    z = x + y\n",
    "    return z\n",
    "```\n",
    "\n",
    "After `def` is the **function name** (`add`; what you use to call it later). Inside the parentheses are the **arguments** (`x` and `y`), which are variables that are available inside the function. The indented part is the **function body**. At the end of the function body is a **return statement** that specifies the **return value** after `return`.\n",
    "\n",
    "For simple functions you can put the interesting part on the return statement and avoid creating some new variables. For instance, the following is equivalent:\n",
    "\n",
    "```python\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Case-normalization\n",
    "\n",
    "In this part you will explore how case normalization affects frequency distributions by writing functions to return normalized tokens. You may find the following string methods useful:\n",
    "\n",
    "- [str.split()][] -- break up a string at whitespace and return a list of tokens\n",
    "- [str.lower()][]/[str.upper()][] -- return a string with only lower-/upper-case letters\n",
    "\n",
    "[str.split()]: https://docs.python.org/3/library/stdtypes.html#str.split\n",
    "[str.lower()]: https://docs.python.org/3/library/stdtypes.html#str.lower\n",
    "[str.upper()]: https://docs.python.org/3/library/stdtypes.html#str.upper\n",
    "\n",
    "Note: [str](https://docs.python.org/3/library/stdtypes.html#str) is just the string type in Python. When you call these methods, you replace `str` with an actual quoted string or string variable, e.g., `'hi'.upper()` or `my_string.split()`.\n",
    "\n",
    "For example, run the following to see how they work (this part is not graded):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', 'two', 'three']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'one two three'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower UPPER\n"
     ]
    }
   ],
   "source": [
    "print('LoWeR'.lower(), 'UpPeR'.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now wrap these string methods in functions that work on a string argument. I have provided the scaffolding for the functions. All you need to provide is the function body and a return statement. (this part is graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "256189e09e11ab244d49c6231ca6dc4d",
     "grade": false,
     "grade_id": "cell-c8248f64eeac8e49",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    \"\"\"Return the list of all the tokens in string *s*.\"\"\"\n",
    "    return s.split()\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def normalize(s):\n",
    "    \"\"\"Return the case-normalized string for *s*.\"\"\"\n",
    "    return s.lower()\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nde colores, de colores\\nse visten los campos en la primavera.\\n\\nde colores, de colores\\nson los pajaritos que vienen de afuera.\\n\\nde colores, de colores\\nes el arco iris que vemos lucir.\\n\\ny por eso los grandes amores\\nde muchos colores me gustan a mí.\\n\\ny por eso los grandes amores\\nde muchos colores me gustan a mí.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(de_colores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the following to ensure the tests pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0b966faee4480e94ebbf24c24d0ce922",
     "grade": true,
     "grade_id": "cell-d8a9c800a71ec7ee",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert tokenize('one') == ['one']\n",
    "assert tokenize('one two') == ['one', 'two']\n",
    "assert tokenize('two one') == ['two', 'one']\n",
    "assert tokenize('') == []\n",
    "assert len(tokenize(de_colores)) == 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0f7f8c3bf1c9b330fcb8773f8f8c3f60",
     "grade": true,
     "grade_id": "cell-d6e2f1c72f972d80",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert normalize('ABC') == 'abc'\n",
    "assert normalize('abc') == 'abc'\n",
    "assert normalize('') == ''\n",
    "assert normalize(de_colores).split()[0] == 'de'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use `nltk.FreqDist` and the functions you wrote above to create a frequency distribution of the raw (not normalized) tokens in a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c90a0b8d0cf1912ff3ed35a1985541cb",
     "grade": false,
     "grade_id": "cell-f32c7a112635ce41",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from nltk.book import *\n",
    "\n",
    "def token_frequencies(s):\n",
    "    \"\"\"Return an nltk.FreqDist of the tokens in string *s*.\"\"\"\n",
    "    return FreqDist(tokenize(s))\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f8ddb957bf7c0260079ce497d72dc919",
     "grade": true,
     "grade_id": "cell-1f63d520cfd07a34",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "raw = token_frequencies(de_colores)\n",
    "assert raw['De'] == 5\n",
    "assert raw['de'] == 4\n",
    "assert raw['colores'] == 5\n",
    "assert raw['colores,'] == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a frequency distribution using normalized tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "56ff44e7ae37d10c63b285f27a401013",
     "grade": false,
     "grade_id": "cell-5c59ebdda7530d34",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def normalized_token_frequencies(s):\n",
    "    \"\"\"Return an nltk.FreqDist of the tokens in string *s*.\"\"\"\n",
    "    return FreqDist(normalize(s).split())\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "522fbad2405ce54430d14c2c48871333",
     "grade": true,
     "grade_id": "test_normalized_tokens",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "normalized = normalized_token_frequencies(de_colores)\n",
    "assert normalized['de'] == 9\n",
    "assert normalized['De'] == 0\n",
    "assert normalized['colores'] == 5\n",
    "assert normalized['colores,'] == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the different frequencies between the raw and normalized distributions. Why does normalizing change the distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3846354faecb5c4101a847904dfae35c",
     "grade": true,
     "grade_id": "cell-41a2a9d6ece210c5",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Because normalizing collapses capitalized and non-capitalized versions of the same word into one category, unlike raw distributions, which regard the two as distinct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at tokens whose frequencies did not change. What other kinds of normalization might help you to get more accurate word frequencies? (Alternatively: what normalization strategies might help languages other than Spanish or English?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "40c4ab38f5494dec8bfa93f98213e5a5",
     "grade": true,
     "grade_id": "cell-d4f7bf38a8cda2cc",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Split the data into individual words by using a function like word_tokenize rather than using spaces to define word boundaries. For other languages, it might be necessary to have access to a something like a corpus that the data can be checked against so that multiple characters that form a single word are not split up, and other features unique to a language (like particles) will not be overlooked."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
